{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "esp32_ip = \"192.168.136.12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(t):\n",
    "    esp32_ip = \"192.168.78.12\"\n",
    "    try:\n",
    "        response = requests.get(f\"http://{esp32_ip}/led/{t}\")\n",
    "        print(response.text)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"ESP32 performed the task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cv2.CascadeClassifier(\"haarcascade_frontalface_default copy.xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.startWindowThread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "Detect = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\91892\\Desktop\\shobhii\\Team Vision IPIC\\HumanDetection.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame,cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m faces \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mdetectMultiScale(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     gray,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     scaleFactor\u001b[39m=\u001b[39;49m \u001b[39m1.1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     minNeighbors \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     minSize \u001b[39m=\u001b[39;49m (\u001b[39m30\u001b[39;49m,\u001b[39m30\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     flags \u001b[39m=\u001b[39;49m cv2\u001b[39m.\u001b[39;49mCASCADE_SCALE_IMAGE\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m (x,y,w,h) \u001b[39min\u001b[39;00m faces:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91892/Desktop/shobhii/Team%20Vision%20IPIC/HumanDetection.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     cv2\u001b[39m.\u001b[39mrectangle(frame,(x,y),(x\u001b[39m+\u001b[39mw,y\u001b[39m+\u001b[39mh),(\u001b[39m255\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m),\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # using a greyscale picture, also for faster detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = clf.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor= 1.1,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (30,30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    \n",
    "    # Write the output video \n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if len(faces) >=1:\n",
    "        detect =True\n",
    "    else:\n",
    "        detect = False\n",
    "    #print(detect)\n",
    "    if detect:\n",
    "        start_time = time.time()\n",
    "        while time.time()-start_time<1:\n",
    "            ret, frame = cap.read()\n",
    "            frame = cv2.resize(frame, (640, 480))\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            faces = clf.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor= 1.1,\n",
    "                minNeighbors = 5,\n",
    "                minSize = (30,30),\n",
    "                flags = cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "            if len(faces)==0:\n",
    "                detect = False\n",
    "                break\n",
    "    elif not detect:\n",
    "        start_time = time.time()\n",
    "        while time.time()-start_time<1:\n",
    "            ret, frame = cap.read()\n",
    "            frame = cv2.resize(frame, (640, 480))\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            faces = clf.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor= 1.1,\n",
    "                minNeighbors = 5,\n",
    "                minSize = (30,30),\n",
    "                flags = cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "            if len(faces)>0:\n",
    "                detect = True\n",
    "                break    \n",
    "    if detect:\n",
    "        print(\"yes\")\n",
    "        call(\"on\")\n",
    "    else:\n",
    "        print(\"No\")\n",
    "        call(\"off\")\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# and release the output\n",
    "# finally, close the window\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESP32 performed the task\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = requests.get(f\"http://{esp32_ip}/led/off\")\n",
    "    print(response.text)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"ESP32 performed the task\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9edef32df64fbf2445d5eccdfaffa024e9b8b80668c48f61f6609efa82d8ab8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
